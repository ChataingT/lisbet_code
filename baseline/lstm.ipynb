{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from utils import trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout=0.3):\n",
    "        \"\"\"\n",
    "        LSTM model for sequence classification.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of features per time step (e.g., 34 keypoints).\n",
    "            hidden_size (int): Number of LSTM hidden units.\n",
    "            output_size (int): Number of output units (e.g., 1 for binary classification).\n",
    "            num_layers (int): Number of stacked LSTM layers.\n",
    "            dropout (float): Dropout rate between LSTM layers.\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Define LSTM layer(s)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,  # Input shape: (batch, seq_len, input_size)\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Output activation (use sigmoid for binary classification)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the LSTM model.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, seq_len, input_size).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor of shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        # Pass through LSTM\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Use the last hidden state for classification\n",
    "        out = self.fc(out[:, -1, :])  # Get the output of the last time step\n",
    "        \n",
    "        # Apply sigmoid activation for binary classification\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_with_windows(data_list, window_size=200, stride=30):\n",
    "    \"\"\"\n",
    "    Converts the input dictionary into multiple windows for MLP training.\n",
    "    \n",
    "    Args:\n",
    "        data_dict (dict): Dictionary with video data.\n",
    "            - Keys: Video IDs\n",
    "            - Values: {\"keypoints\": np.array of shape (num_frames, 34), \"diag\": binary}\n",
    "        window_size (int): Number of frames per window.\n",
    "        stride (int): Number of frames to slide for the next window.\n",
    "        \n",
    "    Returns:\n",
    "        X (np.array): Flattened input features for MLP of shape (num_windows, 34 * window_size)\n",
    "        y (np.array): Binary labels of shape (num_windows,)\n",
    "    \"\"\"\n",
    "    idx_vid, X, y = [], [], []\n",
    "    \n",
    "    for video_id, video_data in df.groupby('video'):\n",
    "        diag = video_data.iloc[0].diagnosis\n",
    "        vd = video_data.drop(['video', 'diagnosis'], axis=1).to_numpy()\n",
    "        num_frames= len(vd)\n",
    "        \n",
    "        # Create windows\n",
    "        for start in range(0, num_frames - window_size + 1, stride):\n",
    "            window = vd[start : start + window_size]\n",
    "            X.append(window)\n",
    "            y.append(diag)\n",
    "            idx_vid.append(video_id)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return idx_vid, X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r\"C:\\Users\\chataint\\Documents\\projet\\humanlisbet\\datasets\\humans\\humans_train_annoted.h5\"\n",
    "dataval = r\"C:\\Users\\chataint\\Documents\\projet\\humanlisbet\\datasets\\humans\\humans_test_annoted.h5\"\n",
    "out = r\"C:\\Users\\chataint\\Documents\\projet\\humanlisbet\\baseline\\out_lstm\"\n",
    "mapping_path = r\"C:\\Users\\chataint\\Documents\\projet\\humanlisbet\\datasets\\humans\\category_mapping.json\"\n",
    "label_path = r\"C:\\Users\\chataint\\Documents\\projet\\humanlisbet\\datasets\\humans\\humans_annoted.label.json\"\n",
    "\n",
    "os.makedirs(out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INPUT_SIZE = 34  \n",
    "HIDDEN_SIZE = 64\n",
    "WINDOW = 200\n",
    "OUTPUT_SIZE = 1  # Binary classification\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 64\n",
    "seed = 42\n",
    "test_ratio = 0.8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DROPOUT = 0.3\n",
    "verbose = False\n",
    "NUM_LAYER=1\n",
    "\n",
    "# Parameter dictionary\n",
    "run_parameters = {\n",
    "    \"input_size\": INPUT_SIZE,\n",
    "    \"hidden_size\": HIDDEN_SIZE,\n",
    "    \"output_size\": OUTPUT_SIZE,\n",
    "    \"window\": WINDOW,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"seed\": seed,\n",
    "    \"test_ratio\": test_ratio,\n",
    "    \"dropout\": DROPOUT,\n",
    "    \"num_layer\": NUM_LAYER,\n",
    "    \"verbose\": verbose\n",
    "}\n",
    "\n",
    "with open(os.path.join(out, 'parameters.json'), 'w') as fd:\n",
    "    json.dump(run_parameters, fd, indent=4)\n",
    "\n",
    "model = LSTMModel(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE, NUM_LAYER, DROPOUT).to(device)\n",
    "\n",
    "dfm = trainer(out, run_parameters, mapping_path, label_path, datapath, device, dataval, model, process_data_with_windows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, labels = load_h5_data(datapath)\n",
    "rec_train, rec_test = train_test_split(\n",
    "            records, test_size=test_ratio, random_state=seed, stratify=labels\n",
    "        )\n",
    "\n",
    "with open(mapping_path, 'r') as fd:\n",
    "    mapping = json.load(fd)\n",
    "\n",
    "mapping = {int(key):value for key,value in mapping.items()}\n",
    "\n",
    "with open(os.path.join(out, \"rec_test\"), 'wb') as fd:\n",
    "    pickle.dump(rec_test, fd)\n",
    "with open(os.path.join(out, \"rec_train\"), 'wb') as fd:\n",
    "    pickle.dump(rec_train, fd)\n",
    "\n",
    "idx_vid_test, X_test, y_test = process_data_with_windows(rec_test)\n",
    "idx_vid_train, X_train, y_train = process_data_with_windows(rec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chataint\\AppData\\Local\\anaconda3\\envs\\diffversify\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566e4e6b6cb84c3f93346b69191b0bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. Training terminated. Best model at 9 with score=0.6149729042617247\n",
      "Epoch 30/500, Loss: 0.6558 Validation - Accuracy: 0.5090, Precision: 0.4842, Recall: 0.6198, F1: 0.5437\n"
     ]
    }
   ],
   "source": [
    "dataset = AutismDataset(X_train, y_train, idx_vid_train, device=device)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "dataset_test = AutismDataset(X_test, y_test, idx_vid_test, device=device)\n",
    "test_loader = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss, and optimizer\n",
    "model = LSTMModel(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE, NUM_LAYER, DROPOUT).to(device)\n",
    "\n",
    "pos_weight = torch.tensor(((y_train.squeeze() -1).sum() *-1) / y_train.squeeze().sum())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "early_stopping = EarlyStoppingMetric(patience=20, verbose=verbose, path=os.path.join(out, 'best_model.pth'), warm_up=1)\n",
    "\n",
    "dfm = pd.DataFrame()\n",
    "# Training loop\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Training Progress\", unit=\"epoch\"):\n",
    "    metrics = {'epoch':epoch}\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (batch_X, batch_y, _) in tqdm(enumerate(train_loader), \n",
    "                                              total=len(train_loader), \n",
    "                                              desc=f\"Training {epoch + 1}\", \n",
    "                                              leave=False, disable=not(verbose)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X).squeeze()\n",
    "        loss = criterion(outputs, batch_y.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Adjust learning rate\n",
    "    scheduler.step(epoch_loss)\n",
    "\n",
    "    metrics['loss']=epoch_loss / len(train_loader)\n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_targets, test_predictions, videos, test_loss = [], [], [], 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch_X, batch_y, idx_video) in tqdm(enumerate(test_loader), \n",
    "                                              total=len(test_loader), \n",
    "                                              desc=f\"Validation {epoch + 1}\", \n",
    "                                              leave=False, disable=not(verbose)):\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_X).squeeze()\n",
    "            loss = criterion(outputs, batch_y.squeeze())\n",
    "            test_loss += loss\n",
    "            if outputs.dim() == 0:\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "            \n",
    "            # Store predictions and targets\n",
    "            test_predictions.extend(torch.round(outputs).cpu().numpy())  # Convert logits to binary predictions\n",
    "            test_targets.extend(batch_y.cpu().numpy())\n",
    "            videos.extend(idx_video)\n",
    "    \n",
    "    test_loss = test_loss.cpu().numpy() / len(test_loader)\n",
    "    # Compute validation metrics\n",
    "    val_accuracy = accuracy_score(test_targets, test_predictions)\n",
    "    val_precision = precision_score(test_targets, test_predictions, zero_division=0)\n",
    "    val_recall = recall_score(test_targets, test_predictions, zero_division=0)\n",
    "    val_f1 = f1_score(test_targets, test_predictions, zero_division=0)\n",
    "\n",
    "    if verbose:\n",
    "        tqdm.write(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {epoch_loss / len(train_loader):.4f} Validation - Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "        \n",
    "    if True:\n",
    "        debug_metrics(test_targets, test_predictions, videos, mapping, epoch, out)\n",
    "    metrics['acc'] = val_accuracy\n",
    "    metrics['prec'] = val_precision\n",
    "    metrics['rec'] = val_recall\n",
    "    metrics['f1'] = val_f1\n",
    "    metrics['test_loss'] = test_loss\n",
    "\n",
    "    dfm = pd.concat([dfm, pd.DataFrame(metrics, index=[0])], ignore_index=True)\n",
    "\n",
    "    # Check early stopping\n",
    "    found_best = early_stopping(metric=val_f1, model=model, epoch=epoch)\n",
    "    if found_best:\n",
    "        get_metrics(test_targets, test_predictions, videos, mapping, out)\n",
    "    # early_stopping(test_loss=test_loss, model=model, epoch=epoch)\n",
    "    if early_stopping.early_stop:\n",
    "        tqdm.write(f\"Early stopping triggered. Training terminated. Best model at {early_stopping.best_epoch} with score={early_stopping.best_score}\")\n",
    "        break\n",
    "\n",
    "print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {epoch_loss / len(train_loader):.4f} Validation - Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), os.path.join(out,\"last_model.pth\"))\n",
    "dfm.to_csv(os.path.join(out, 'metrics.csv'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, labels = load_h5_data(dataval)\n",
    "\n",
    "idx_vid_val, X_val, y_val = process_data_with_windows(records)\n",
    "y_val = y_val.squeeze()\n",
    "\n",
    "db_val = AutismDataset(X_val, y_val,idx_vid_val, device=device)\n",
    "val_loader = DataLoader(db_val, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, videos = [], [],[]\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (batch_X, batch_y, idx_video) in tqdm(enumerate(val_loader), \n",
    "                                              total=len(val_loader), \n",
    "                                              desc=f\"Validation\", \n",
    "                                              leave=False, disable=not(verbose)):\n",
    "        y_pred.extend(model(batch_X).cpu().numpy().squeeze().round())\n",
    "        y_true.extend(batch_y.cpu().numpy().squeeze())\n",
    "        videos.extend(idx_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8104</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8117</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8121</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8124</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8127</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8130</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8133</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8107</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8137</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8155</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8156</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8162</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8187</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8201</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8204</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8141</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8207</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8208</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8100</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7965</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7978</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8101</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8042</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8046</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8029</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8058</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8062</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8076</td>\n",
       "      <td>ASD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8081</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8055</td>\n",
       "      <td>TD</td>\n",
       "      <td>ASD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8002</td>\n",
       "      <td>TD</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7982</td>\n",
       "      <td>TD</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7954</td>\n",
       "      <td>ASD</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7947</td>\n",
       "      <td>TD</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7772</td>\n",
       "      <td>ASD</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video y_pred y_true\n",
       "0   8104     TD    ASD\n",
       "1   8117    ASD    ASD\n",
       "2   8121    ASD    ASD\n",
       "3   8124     TD    ASD\n",
       "4   8127     TD    ASD\n",
       "5   8130     TD    ASD\n",
       "6   8133    ASD    ASD\n",
       "7   8107     TD    ASD\n",
       "8   8137    ASD    ASD\n",
       "9   8155     TD    ASD\n",
       "10  8156     TD    ASD\n",
       "11  8162     TD    ASD\n",
       "12  8187     TD    ASD\n",
       "13  8201     TD    ASD\n",
       "14  8204    ASD    ASD\n",
       "15  8141    ASD    ASD\n",
       "16  8207     TD    ASD\n",
       "17  8208    ASD    ASD\n",
       "18  8100     TD    ASD\n",
       "19  7965     TD    ASD\n",
       "20  7978     TD    ASD\n",
       "21  8101     TD    ASD\n",
       "22  8042     TD    ASD\n",
       "23  8046     TD    ASD\n",
       "24  8029    ASD    ASD\n",
       "25  8058     TD    ASD\n",
       "26  8062    ASD    ASD\n",
       "27  8076    ASD    ASD\n",
       "28  8081     TD    ASD\n",
       "29  8055     TD    ASD\n",
       "30  8002     TD     TD\n",
       "31  7982     TD     TD\n",
       "32  7954    ASD     TD\n",
       "33  7947     TD     TD\n",
       "34  7772    ASD     TD"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_validation(y_true, y_pred, videos, out, mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffversify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
