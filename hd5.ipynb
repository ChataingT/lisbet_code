{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for human lisbet experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"./datasets/humans\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(root, \"humans_TD.h5\")\n",
    "a=h5py.File(filename)\n",
    "\n",
    "d_TD = []\n",
    "for key, vh in a.items():\n",
    "    data = a[key]['keypoints'][()]\n",
    "    point = (key, {'keypoints':data})\n",
    "    d_TD.append(point)\n",
    "a.close()\n",
    "print(len(d_TD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(root, \"humans_ASD.h5\")\n",
    "a=h5py.File(filename)\n",
    "\n",
    "d_ASD = []\n",
    "for key, vh in a.items():\n",
    "    data = a[key]['keypoints'][()]\n",
    "    point = (key, {'keypoints':data})\n",
    "    d_ASD.append(point)\n",
    "a.close()\n",
    "print(len(d_ASD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1 all\n",
    "d5 = d_TD + d_ASD\n",
    "\n",
    "filename = os.path.join(root, \"humans_all.h5\")\n",
    "\n",
    "with h5py.File(filename, 'w') as fd:\n",
    "    for key, val in d5:\n",
    "        fd.create_dataset(f\"{key}/keypoints\", data=val[\"keypoints\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(root, \"humans_all.h5\")\n",
    "\n",
    "with h5py.File(filename, 'r') as fd:\n",
    "\n",
    "    d_5 = []\n",
    "    for key, vh in fd.items():\n",
    "        data = fd[key]['keypoints'][()]\n",
    "        point = (key, {'keypoints':data})\n",
    "        d_5.append(point)\n",
    "\n",
    "print(len(d_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1 50/50\n",
    "size = min(len(d_TD), len(d_ASD))\n",
    "random.seed(SEED)\n",
    "random.shuffle(d_TD)\n",
    "random.shuffle(d_ASD)\n",
    "d5 = d_TD[:size] + d_ASD[:size]\n",
    "\n",
    "filename = os.path.join(root, \"humans_50-50.h5\")\n",
    "\n",
    "with h5py.File(filename, 'w') as fd:\n",
    "    for key, val in d5:\n",
    "        fd.create_dataset(f\"{key}/keypoints\", data=val[\"keypoints\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(root, \"humans_50-50.h5\")\n",
    "\n",
    "with h5py.File(filename, 'r') as fd:\n",
    "\n",
    "    d_5 = []\n",
    "    for key, vh in fd.items():\n",
    "        data = fd[key]['keypoints'][()]\n",
    "        point = (key, {'keypoints':data})\n",
    "        d_5.append(point)\n",
    "\n",
    "print(len(d_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d_5 = []\n",
    "dm = pd.read_excel(os.path.join(root, r\"data_mapping.xlsx\"), dtype=str)\n",
    "dm = dm[dm['From']=='Sara'] \n",
    "\n",
    "dm = dm.drop_duplicates()\n",
    "\n",
    "\n",
    "dm['video'] = dm['VCFS_DATABASE_ADMIN 2::Sujet_ID']\n",
    "dm['diagnosis'] = dm['VCFS_DATABASE_ADMIN 2::Diagnosis']\n",
    "dm['diagnosis'] = dm['diagnosis'].replace({'Low-Risk':'TD'})\n",
    "dm['diagnosis'] = dm['diagnosis'].replace({'Normal_Control':'TD'})\n",
    "dm['diagnosis'] = dm['diagnosis'].replace({'Autism':'ASD'})\n",
    "\n",
    "dm['diagnosis'] = dm['diagnosis'].astype('category')\n",
    "\n",
    "dm['diag_int'] = dm['diagnosis'].cat.codes\n",
    "category_mapping = dict(enumerate(dm['diagnosis'].cat.categories))\n",
    "\n",
    "for id, vid_dic in d_5:\n",
    "    vid_dic['diag'] = dm[dm['video']==id]['diag_int'].to_numpy()\n",
    "    new_d_5.append((id, vid_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(root, \"humans_50-50_annoted.h5\")\n",
    "\n",
    "with h5py.File(filename, 'w') as fd:\n",
    "    for key, val in new_d_5:\n",
    "        ds = fd.create_dataset(f\"{key}/keypoints\", data=val[\"keypoints\"])\n",
    "        ds.attrs.create('diag', data=val[\"diag\"])\n",
    "\n",
    "\n",
    "filename = os.path.join(root, \"humans_50-50_annoted.mapping.json\")\n",
    "with open(filename, 'w') as fd:\n",
    "    json.dump(category_mapping, fd, indent=4)\n",
    "\n",
    "filename = os.path.join(root, \"humans_50-50_annoted.label.json\")\n",
    "with open(filename, 'w') as fd:\n",
    "    json.dump(dm[['diagnosis', 'video']].to_dict(), fd, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diagnosis': {0: 'TD',\n",
       "  2: 'TD',\n",
       "  3: 'TD',\n",
       "  4: 'ASD',\n",
       "  5: 'ASD',\n",
       "  6: 'TD',\n",
       "  8: 'TD',\n",
       "  9: 'TD',\n",
       "  10: 'TD',\n",
       "  11: 'TD',\n",
       "  12: 'ASD',\n",
       "  13: 'TD',\n",
       "  14: 'ASD',\n",
       "  15: 'ASD',\n",
       "  16: 'TD',\n",
       "  17: 'ASD',\n",
       "  18: 'ASD',\n",
       "  19: 'ASD',\n",
       "  22: 'TD',\n",
       "  23: 'TD',\n",
       "  24: 'TD',\n",
       "  25: 'ASD',\n",
       "  27: 'ASD',\n",
       "  30: 'ASD',\n",
       "  31: 'ASD',\n",
       "  32: 'ASD',\n",
       "  33: 'ASD',\n",
       "  37: 'ASD',\n",
       "  38: 'ASD',\n",
       "  39: 'ASD',\n",
       "  41: 'ASD',\n",
       "  42: 'ASD',\n",
       "  43: 'ASD',\n",
       "  45: 'ASD',\n",
       "  47: 'ASD',\n",
       "  48: 'TD',\n",
       "  49: 'ASD',\n",
       "  50: 'ASD',\n",
       "  51: 'TD',\n",
       "  52: 'TD',\n",
       "  53: 'ASD',\n",
       "  54: 'TD',\n",
       "  56: 'TD',\n",
       "  58: 'TD',\n",
       "  59: 'TD',\n",
       "  60: 'ASD',\n",
       "  61: 'TD',\n",
       "  62: 'TD',\n",
       "  63: 'ASD',\n",
       "  64: 'ASD',\n",
       "  66: 'ASD',\n",
       "  67: 'ASD',\n",
       "  68: 'ASD',\n",
       "  69: 'TD',\n",
       "  70: 'ASD',\n",
       "  72: 'ASD',\n",
       "  73: 'ASD',\n",
       "  74: 'ASD',\n",
       "  76: 'TD',\n",
       "  77: 'TD',\n",
       "  78: 'ASD',\n",
       "  79: 'ASD',\n",
       "  80: 'ASD',\n",
       "  81: 'ASD',\n",
       "  82: 'ASD',\n",
       "  83: 'ASD',\n",
       "  84: 'ASD',\n",
       "  85: 'ASD',\n",
       "  86: 'ASD',\n",
       "  87: 'ASD',\n",
       "  88: 'ASD',\n",
       "  89: 'ASD',\n",
       "  90: 'ASD',\n",
       "  91: 'ASD',\n",
       "  92: 'ASD',\n",
       "  93: 'ASD',\n",
       "  94: 'ASD',\n",
       "  95: 'ASD',\n",
       "  96: 'ASD',\n",
       "  98: 'ASD',\n",
       "  99: 'ASD',\n",
       "  101: 'ASD',\n",
       "  102: 'ASD',\n",
       "  105: 'ASD',\n",
       "  107: 'TD',\n",
       "  108: 'TD',\n",
       "  109: 'TD',\n",
       "  110: 'TD',\n",
       "  111: 'ASD',\n",
       "  112: 'TD'},\n",
       " 'video': {0: '7772',\n",
       "  2: '7947',\n",
       "  3: '7954',\n",
       "  4: '7965',\n",
       "  5: '7978',\n",
       "  6: '7982',\n",
       "  8: '8002',\n",
       "  9: '8017',\n",
       "  10: '8018',\n",
       "  11: '8019',\n",
       "  12: '8029',\n",
       "  13: '8031',\n",
       "  14: '8042',\n",
       "  15: '8046',\n",
       "  16: '8054',\n",
       "  17: '8055',\n",
       "  18: '8058',\n",
       "  19: '8062',\n",
       "  22: '8072',\n",
       "  23: '8073',\n",
       "  24: '8075',\n",
       "  25: '8076',\n",
       "  27: '8081',\n",
       "  30: '8100',\n",
       "  31: '8101',\n",
       "  32: '8104',\n",
       "  33: '8107',\n",
       "  37: '8117',\n",
       "  38: '8121',\n",
       "  39: '8124',\n",
       "  41: '8127',\n",
       "  42: '8130',\n",
       "  43: '8133',\n",
       "  45: '8137',\n",
       "  47: '8141',\n",
       "  48: '8149',\n",
       "  49: '8155',\n",
       "  50: '8156',\n",
       "  51: '8157',\n",
       "  52: '8158',\n",
       "  53: '8162',\n",
       "  54: '8165',\n",
       "  56: '8174',\n",
       "  58: '8183',\n",
       "  59: '8185',\n",
       "  60: '8187',\n",
       "  61: '8188',\n",
       "  62: '8200',\n",
       "  63: '8201',\n",
       "  64: '8204',\n",
       "  66: '8207',\n",
       "  67: '8208',\n",
       "  68: '8211',\n",
       "  69: '8216',\n",
       "  70: '8222',\n",
       "  72: '8234',\n",
       "  73: '8244',\n",
       "  74: '8246',\n",
       "  76: '8249',\n",
       "  77: '8252',\n",
       "  78: '8253',\n",
       "  79: '8279',\n",
       "  80: '8281',\n",
       "  81: '8288',\n",
       "  82: '8294',\n",
       "  83: '8295',\n",
       "  84: '8296',\n",
       "  85: '8297',\n",
       "  86: '8298',\n",
       "  87: '8299',\n",
       "  88: '8300',\n",
       "  89: '8301',\n",
       "  90: '8306',\n",
       "  91: '8307',\n",
       "  92: '8310',\n",
       "  93: '8311',\n",
       "  94: '8317',\n",
       "  95: '8318',\n",
       "  96: '8333',\n",
       "  98: '8334',\n",
       "  99: '8335',\n",
       "  101: '8337',\n",
       "  102: '8344',\n",
       "  105: '8349',\n",
       "  107: '8355',\n",
       "  108: '8358',\n",
       "  109: '8359',\n",
       "  110: '8360',\n",
       "  111: '8372',\n",
       "  112: '8378'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm[['diagnosis', 'video']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to try and shuffle id\n",
    "\n",
    "# d_n = []\n",
    "\n",
    "# proba_shuffle = 1\n",
    "# seed = 42\n",
    "# random.seed(seed)\n",
    "# for frame_id, dict_keyp in d_5:\n",
    "#     keypoints = dict_keyp['keypoints']\n",
    "#     new_kp = keypoints.copy()\n",
    "#     for i in range(len(keypoints)):\n",
    "#         if random.random() < proba_shuffle:\n",
    "#             new_kp[i] = np.concatenate((keypoints[i][17:], keypoints[i][:17]))\n",
    "\n",
    "#     d_n.append((frame_id, {'keypoints':new_kp}))\n",
    "\n",
    "# filename = os.path.join(root, \"humans_50-50_skeletonIDshuffle_p100.h5\")\n",
    "\n",
    "# with h5py.File(filename, 'w') as fd:\n",
    "#     for key, val in d_n:\n",
    "#         fd.create_dataset(f\"{key}/keypoints\", data=val[\"keypoints\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "# filename = os.path.join(root, \"humans_50-50_skeletonIDshuffle_p50.h5\")\n",
    "\n",
    "# with h5py.File(filename, 'r') as fd:\n",
    "\n",
    "#     d_5 = []\n",
    "#     for key, vh in fd.items():\n",
    "#         data = fd[key]['keypoints'][()]\n",
    "#         point = (key, {'keypoints':data})\n",
    "#         d_5.append(point)\n",
    "\n",
    "# print(len(d_5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humanlisbet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
